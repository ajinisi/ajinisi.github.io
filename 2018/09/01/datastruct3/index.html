<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>数据结构和算法之海量数据处理 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="在处理海量数据问题时，首先要仔细分析问题，明白问题需要解决那些关键问题，明白需要达到怎样的存储、性能要求，在这之前，应充分理解业务数据的分布、数据粒度、数据服务的质量要求、数据的动态性、数据的关联性等真实数据、业务熟悉。通常我认为，处理海量数据问题时，心中要有一些基本概念：  现有的开源的优秀工具那些是处理海量数据的； 海量数据就因为数据大吗，可以考虑对海量数据进行分区操作； 加快海量数据的访问，">
<meta property="og:type" content="article">
<meta property="og:title" content="数据结构和算法之海量数据处理">
<meta property="og:url" content="http://yoursite.com/2018/09/01/datastruct3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="在处理海量数据问题时，首先要仔细分析问题，明白问题需要解决那些关键问题，明白需要达到怎样的存储、性能要求，在这之前，应充分理解业务数据的分布、数据粒度、数据服务的质量要求、数据的动态性、数据的关联性等真实数据、业务熟悉。通常我认为，处理海量数据问题时，心中要有一些基本概念：  现有的开源的优秀工具那些是处理海量数据的； 海量数据就因为数据大吗，可以考虑对海量数据进行分区操作； 加快海量数据的访问，">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-09-02T13:56:57.802Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据结构和算法之海量数据处理">
<meta name="twitter:description" content="在处理海量数据问题时，首先要仔细分析问题，明白问题需要解决那些关键问题，明白需要达到怎样的存储、性能要求，在这之前，应充分理解业务数据的分布、数据粒度、数据服务的质量要求、数据的动态性、数据的关联性等真实数据、业务熟悉。通常我认为，处理海量数据问题时，心中要有一些基本概念：  现有的开源的优秀工具那些是处理海量数据的； 海量数据就因为数据大吗，可以考虑对海量数据进行分区操作； 加快海量数据的访问，">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-datastruct3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/01/datastruct3/" class="article-date">
  <time datetime="2018-09-01T13:43:27.623Z" itemprop="datePublished">2018-09-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      数据结构和算法之海量数据处理
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在处理海量数据问题时，首先要仔细分析问题，明白问题需要解决那些关键问题，明白需要达到怎样的存储、性能要求，在这之前，应充分理解业务数据的分布、数据粒度、数据服务的质量要求、数据的动态性、数据的关联性等真实数据、业务熟悉。通常我认为，处理海量数据问题时，心中要有一些基本概念：</p>
<ol>
<li>现有的开源的优秀工具那些是处理海量数据的；</li>
<li>海量数据就因为数据大吗，可以考虑对海量数据进行分区操作；</li>
<li>加快海量数据的访问，数据索引必不可是；</li>
<li>内存总是有限的，内存的速度是最好的，建立缓存机制是十分必要的；</li>
<li>海量数据来源多样，数据格式也不相同，最好是统一为字符串处理，逻辑处理交给上层应用；</li>
<li>海量数据离不开集群、分布式，分布式的出错处理、负载均衡就必然要有一套可行的机制；</li>
<li>所有底层的问题或者说存储的问题解决了，未来方便上层应用或者夸大底层支持的业务，对外应该有一个明朗的逻辑视图；</li>
<li>系统设计和结构，会因为不同的语言、操作性在实现难以上不同，这也需要考虑；</li>
<li>海量数据的一个应用就是数据挖掘服务，多域数据来源统一管理下，数据仓库和相关计算也应该了解一二；</li>
<li>尽管说存储不是问题，如果能对数据进行压缩处理，又可以接受的性能，这何乐而不为呢。<br>在参考前人博客、文摘加上个人一点理解，汇总以下一些基础概念已帮助和我一样面临就业的学生，应对未来公司的面试考核。当然，有实际工作经验的大牛门来说，下面的问题早已不是问题，他们都在某个问题上是专家了。欢迎大牛指导！</li>
</ol>
<p>具有通用性的数据结构和算法思路汇总有：</p>
<ol>
<li>Bloom filter</li>
<li>Hashing：海量数据处理离不开hash，hash取模是一种等价映射</li>
<li>bit-map：位图法比较适合于这种情况，它的做法是按照集合中最大元素max创建一个长度为max+1的新数组，然后再次扫描原数组，遇到几就给新数组的第几位置上1，如遇到5就给新数组的第六个元素置1，这样下次再遇到5想置位时发现新数组的第六个元素已经是1了，这说明这次的数据肯定和以前的数据存在着重复。这种给新数组初始化时置零其后置一的做法类似于位图的处理方法故称位图法。它的运算次数最坏的情况为2N。如果已知数组的最大值即能事先给新数组定长的话效率还能提高一倍</li>
<li>堆</li>
<li>双层桶划分，可以理解为多级索引</li>
<li>数据库索引</li>
<li>倒排索引(Inverted index)</li>
<li>外排序</li>
<li>trie树</li>
<li>分布式处理：MapReduce</li>
</ol>
<p>问题：<br>有两亿用户，可以获得每个用户的登录和退出时间，保存在文件中。。要求统计每一秒有多少在线用户</p>
<p>解答：<br>一天总共有 3600*24 = 86400秒<br>定义一个长度为86400的整数数组int delta[86400]，每个整数对应这一秒的人数变化值，可能为正也可能为负。开始时将数组元素都初始化为0。</p>
<p>然后依次读入每个用户的登录时间和退出时间。扫描整个日志，如果这一秒用户处于登录时间，则将dalta[i]整数值加1，将与退出时间对应的整数值减1。从而记录下这一天中第i秒时有多少在线用户。（可能登陆用户多余退出用户，或者相反）。</p>
<p>再定义一个长度为86400的整数数组int online_num[86400]，每个整数对应这一秒的论坛在线人数。</p>
<p>假设一天开始时论坛在线人数为0，则第1秒的人数<br>online_num[0] = delta[0]<br>第n+1秒的人数<br>online_num[n] = online_num[n-1] + delta[n]</p>
<h3 id="找出重复问题"><a href="#找出重复问题" class="headerlink" title="找出重复问题"></a>找出重复问题</h3><p>在海量数据中查找出重复出现的元素或者去除重复出现的元素也是常考的问题</p>
<p>问题：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？<br>    分析：每个url64字节，每个文件50亿url，则每个文件5G*64Byte=320GB，远超内存4G，所以不能将其全部加载到内存中来进行处理，需要采用分而治之的方法进行处理<br>    分治：逐行读取文件a，采用hash函数，Hash(url)%1000将url分割到1000个小文件中，文件即为f1_1,f1_2,f1_3,…,f1_1000，每个小文件中模1000的余数相同，那么理想情况下每个小文件的大小大约为300M左右。再以相同的方法对大文件b进行相同的操作再得到1000个小文件，记为： f2_1,f2_2,f2_3,…,f2_1000</p>
<pre><code>查找：现在，相同的url都分割到了这2组小文件中下标相同的两个文件中，f1_1&amp;  f2_1，  f1_2&amp;  ,f2_2,  f1_3&amp;  f2_3,...,  f1_1000&amp; f2_1000，在每对小文件中，将较小的文件中的url放入HashSet中，然后遍历对应这个小文件中的另一个文件，看其中的url是否存在刚刚构建的HashSet中，如果存在说明是一样的url，将这url直接存到结果文件就ok了。


如果允许有一定的错误率，可以使用Bloom filter，使用位数组，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否在Bloom filter中。如果是，那么该url应该是共同的url（注意会有一定的错误率）
</code></pre><p>问题：有10亿个URL，每个URL对应一个非常大的网页，怎样检测重复的网页？</p>
<pre><code>分析：不同的URL可能对应相同的网页，所以要对网页求Hash。10G个URL+哈希值，总量为几十G，单机内存无法处理
分治：根据Hash(URL)%1000，将URL和网页的哈希值分割到1000个小文件中，注意：重复的网页必定在同一个小文件中
查找：顺序读取每个文件，将Hash值加入HashSet，如果已存在则为重复网页，把对应的URL提取出来
</code></pre><p>问题：在2.5亿个整数中找出 <strong>不重复</strong> 的整数</p>
<pre><code>使用bloomFilter, bloomFilter判断不重复是100%准确的. 因此时间, 空间效率都很可靠

使用2-Bitmap，每个数分配2bit，00表示无, 01表示出现一次, 10表示出现多次，11表示无意义。共需内存2^32 * 2bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。扫描完事后，查看bitmap，把对应位是01的整数输出即可
</code></pre><h3 id="Top-K海量数据部分"><a href="#Top-K海量数据部分" class="headerlink" title="Top-K海量数据部分"></a>Top-K海量数据部分</h3><p>以下三个题目几乎是一回事，第一题只要找出最大的，第二题要找出最大的100个，第三题要排序</p>
<p>问题：海量日志数据，提取出某日访问次数最多的那个IP</p>
<pre><code>分析：每个IP32bit，世界上所有IP最多2^32=1GB
分治：Hash(IP)%1024
统计频数：逐个读小文件，对于每一个小文件构建一个IP为key，出现次数为value的HashMap，维护一个变量，找出最大值即可
</code></pre><p>问题：有一个1G大小的一个文件，里面每一行是一个词word，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词</p>
<pre><code>分治：对每个词取Hash(word)%1024，按照该值存到1024个小文件中，如果有文件超过了1M则继续分割
统计频数：字符串用Trie树最好
排序：用容量100的最小堆，依次读文件-
</code></pre><p>问题：有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序</p>
<pre><code>分治：当前10个文件的query是散乱分布的, 需要先重新对10个文件做一次hash分流, 生成新的10个文件
统计频数：HashMap
排序：利用快速/堆/归并排序对文件进行排序，再对这10个文件进行归并排序（内排序与外排序相结合）
</code></pre><p>问题：从海量数据中找出最大的前k个数</p>
<p>hash：如果这1亿个数里面有很多重复的数，先通过Hash法，把这1亿个数字去重复</p>
<p>分治法：将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的100*10000个数据里面找出最大的10000个。如果100万数据选择足够理想，那么可以过滤掉1亿数据里面99%的数据</p>
<h3 id="bit海量数据部分"><a href="#bit海量数据部分" class="headerlink" title="bit海量数据部分"></a>bit海量数据部分</h3><p>问题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？<br>解答1：<br>使用Bitmap：申请512M内存，一个bit位代表一个unsigned int值，读40亿个数，设置相应bit位，读入要查询的数，查看bit是否为1，若为1表示存在否则表示不存在，时间复杂度O(n)<br>解答2：<br>我们把40亿个数中的每一个用32位的二进制来表示。假设这40亿个数开始放在一个文件中，然后将这40亿个数分成两类：</p>
<ol>
<li>最高位为0    </li>
<li>最高位为1<br>并将这两类分别写入到两个文件中，其中一个文件中数的个数&lt;=20亿，而另一个&gt;=20亿（这相当于折半了）；与要查找的数的最高位比较并接着进入相应的文件再查找。再然后把这个文件为又分成两类:</li>
<li>次最高位为0</li>
<li>次最高位为1<br>并将这两类分别写入到两个文件中，其中一个文件中数的个数&lt;=10亿，而另一个&gt;=10亿（相当于折半）；与要查找的数的次最高位比较并接着进入相应的文件再查找。<br>……<br>以此类推，就可以找到了,而且时间复杂度为O(logn)</li>
</ol>
<p>有200亿条数据，每条数据的大小在1K~1M不等，每条数据有一个唯一的u_int64的id。<br>请设计一个读取数据系统，能根据id获取数据。要求：<br>A.        内存有限制，16G<br>B.        尽可能利用内存资源<br>C.        尽可能高效的获取数据<br>D.        可以利用磁盘，磁盘容量不受限制</p>
<p>分区表，按 id % 1000 分区 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/01/datastruct3/" data-id="cjlofx6qu000a3guzcnv6775p" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/09/03/组成原理_32or64/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          计算机组成原理之32or64
        
      </div>
    </a>
  
  
    <a href="/2018/09/01/designpattern2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/09/11/datastruct_hash/">数据结构和算法之哈希</a>
          </li>
        
          <li>
            <a href="/2018/09/10/Net_HTTP/">计算机网络复习之HTTP</a>
          </li>
        
          <li>
            <a href="/2018/09/08/datastruct4/">数据结构和算法之图</a>
          </li>
        
          <li>
            <a href="/2018/09/06/C++_i/">C++常见问题之i++</a>
          </li>
        
          <li>
            <a href="/2018/09/06/网络编程/">网络编程之同步和异步</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>